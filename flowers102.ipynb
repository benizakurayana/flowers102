{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount to Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Define project folder\n",
    "FOLDERNAME = 'Colab\\ Notebooks/flowers102'\n",
    "\n",
    "%cd drive/MyDrive/$FOLDERNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define device\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# This function calculates mean and std of the dataset\n",
    "def compute_mean_std(loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    num_total_images = 0\n",
    "    \n",
    "    for images, _ in loader:\n",
    "        # images: N x C x H x W (4D)\n",
    "        num_batch_samples = images.size(0)  # N\n",
    "        images = images.reshape(num_batch_samples, images.size(1), -1)  # Reshape to 3D: N x C x (H*W)\n",
    "        \n",
    "        # Mean calculation\n",
    "        # First calculate mean for each image in batch and channel\n",
    "        batch_mean = images.mean(dim=-1)  # N x C\n",
    "        # Then sum over all images in batch\n",
    "        mean += batch_mean.sum(dim=0)  # C\n",
    "        \n",
    "        # Std calculation\n",
    "        # First calculate std for each image in batch and channel\n",
    "        batch_std = images.std(dim=-1)  # N x C\n",
    "        # Then sum over all images in batch\n",
    "        std += batch_std.sum(dim=0)  # C\n",
    "        \n",
    "        num_total_images += num_batch_samples\n",
    "    \n",
    "    mean = mean / num_total_images\n",
    "    std = std / num_total_images\n",
    "    \n",
    "    return mean, std\n",
    "\n",
    "# Define a basic transform just for mean/std calculation\n",
    "basic_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load training dataset with basic transform just for mean/std calculation\n",
    "train_dataset = datasets.Flowers102(root='./train',\n",
    "    split='train',\n",
    "    transform=basic_transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Calculate mean and std of the training dataset\n",
    "loader = DataLoader(train_dataset, batch_size=16, shuffle=False)\n",
    "mean, std = compute_mean_std(loader)\n",
    "print(f\"Dataset mean: {mean}\")\n",
    "print(f\"Dataset std: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2\n",
    "\n",
    "# Define transforms for the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    v2.AutoAugment(policy=v2.AutoAugmentPolicy.IMAGENET),  # AutoAugment with ImageNet policy\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=mean.tolist(),\n",
    "        std=std.tolist()\n",
    "    )\n",
    "])\n",
    "\n",
    "# Load datasets with transforms\n",
    "train_dataset = datasets.Flowers102(root='./train',\n",
    "    split='train',\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "val_dataset = datasets.Flowers102(\n",
    "    root='./val',\n",
    "    split='val',\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "test_dataset = datasets.Flowers102(\n",
    "    root='./test',\n",
    "    split='test',\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
